{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"seat6M6RaPZu","outputId":"d7347ac6-e598-45bb-ccea-0901d01106d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.12.0\n","Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 3s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","y_train shape: (50000, 1)\n","50000 train samples\n","10000 test samples\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 4)         112       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 15, 15, 4)        0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 13, 4)         148       \n","                                                                 \n"," flatten (Flatten)           (None, 676)               0         \n","                                                                 \n"," dense (Dense)               (None, 16)                10832     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                170       \n","                                                                 \n","=================================================================\n","Total params: 11,262\n","Trainable params: 11,262\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/2\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n","  output, from_logits = _get_logits(\n"]},{"name":"stdout","output_type":"stream","text":["4000/4000 [==============================] - 44s 11ms/step - loss: 1.8756 - accuracy: 0.3137 - val_loss: 1.7158 - val_accuracy: 0.3895\n","Epoch 2/2\n","4000/4000 [==============================] - 41s 10ms/step - loss: 1.6559 - accuracy: 0.4046 - val_loss: 1.6445 - val_accuracy: 0.4047\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","import datetime, os\n","\n","\"\"\"\n","Title: Simple MNIST convnet\n","Author: [fchollet](https://twitter.com/fchollet)\n","Date created: 2015/06/19\n","Last modified: 2020/04/21\n","Description: A simple convnet that achieves ~99% test accuracy on MNIST.\n","https://github.com/keras-team/keras-io/blob/master/examples/vision/mnist_convnet.py\n","\"\"\"\n","\n","%load_ext tensorboard\n","\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","\n","# Model / data parameters\n","num_classes = 10\n","input_shape=(32,32,3)\n","cifar10=tf.keras.datasets.cifar10\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Scale images to the [0, 1] range\n","x_train = x_train.astype(\"float32\") / 255\n","x_test = x_test.astype(\"float32\") / 255\n","\n","print(\"x_train shape:\", x_train.shape)\n","print(x_train.shape[0], \"train samples\")\n","print(x_test.shape[0], \"test samples\")\n","\n","# convert class vectors to binary class matrices\n","#y_train = keras.utils.to_categorical(y_train, num_classes)\n","#y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","print(\"y_train shape:\", y_train.shape)\n","print(y_train.shape[0], \"train samples\")\n","print(y_test.shape[0], \"test samples\")\n","\n","\"\"\"\n","## Build the model\n","\"\"\"\n","\n","model = keras.Sequential(\n","    [\n","        keras.Input(shape=input_shape),\n","        layers.Conv2D(4, kernel_size=(3, 3), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2, 2)),\n","        layers.Conv2D(4, kernel_size=(3, 3), activation=\"relu\"),\n","        layers.Flatten(),\n","        layers.Dense(16,activation=\"relu\"),\n","        layers.Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")\n","\n","model.summary()\n","\n","\"\"\"\n","## Train the model\n","\"\"\"\n","\n","batch_size = 10\n","epochs = 2\n","\n","loss_fn1=\"categorical_crossentropy\"\n","\n","#Use SparseCategoricalCrossentropy loss function when there are two or more label classes.\n","#The expect labels are to be provided as integers.\n","loss_fn2=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","\n","#Use CategoricalCrossentropy loss function when there are two or more label classes.\n","#The expect labels are to be provided in a one_hot representation.\n","loss_fn3=tf.keras.losses.CategoricalCrossentropy()\n","\n","model.compile(loss=loss_fn2, optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","\n","\n","model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks=[tensorboard_callback])\n","\n","\"\"\"\n","## Evaluate the trained model\n","\"\"\"\n","\n","\n","%tensorboard --logdir logs\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPLBSSrMT+wG3TJ2lU6aY9F"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}