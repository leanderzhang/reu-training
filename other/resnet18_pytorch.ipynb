{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1cSeOdpHr0uBamehU_TxpBfYFrUMr01Yh","timestamp":1690832000417}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGVLP6MIizKa","executionInfo":{"status":"ok","timestamp":1690832646131,"user_tz":240,"elapsed":1240,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}},"outputId":"db5afc3d-4af5-448c-fb06-447515e3c3af"},"source":["!git clone https://github.com/kuangliu/pytorch-cifar.git"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pytorch-cifar'...\n","remote: Enumerating objects: 382, done.\u001b[K\n","remote: Counting objects: 100% (382/382), done.\u001b[K\n","remote: Compressing objects: 100% (182/182), done.\u001b[K\n","remote: Total 382 (delta 209), reused 355 (delta 197), pack-reused 0\u001b[K\n","Receiving objects: 100% (382/382), 77.42 KiB | 4.84 MiB/s, done.\n","Resolving deltas: 100% (209/209), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58uDR_QLnB87","executionInfo":{"status":"ok","timestamp":1690832938392,"user_tz":240,"elapsed":226,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}},"outputId":"57195f39-82f0-40d6-8bdf-a5d857a560c8"},"source":["%%writefile pytorch-cifar/main.py\n","# main.py\n","'''Train CIFAR10 with PyTorch.'''\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from torchsummary import summary\n","\n","import os\n","import argparse\n","\n","from models import *\n","from utils import progress_bar\n","\n","\n","parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n","parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n","parser.add_argument('--resume', '-r', action='store_true',\n","                    help='resume from checkpoint')\n","args = parser.parse_args()\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","best_acc = 0  # best test accuracy\n","start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n","\n","# Data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(\n","    root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(\n","    root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=100, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer',\n","           'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# Model\n","print('==> Building model..')\n","net = ResNet18()\n","net = net.to(device)\n","if device == 'cuda':\n","    net = torch.nn.DataParallel(net)\n","    cudnn.benchmark = True\n","\n","\n","if args.resume:\n","    # Load checkpoint.\n","    print('==> Resuming from checkpoint..')\n","    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n","    checkpoint = torch.load('./checkpoint/ckpt.pth')\n","    net.load_state_dict(checkpoint['net'])\n","    best_acc = checkpoint['acc']\n","    start_epoch = checkpoint['epoch']\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=args.lr,\n","                      momentum=0.9, weight_decay=5e-4)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n","\n","\n","# Training\n","def train(epoch):\n","    print('\\nEpoch: %d' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","\n","\n","def test(epoch):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","    if acc > best_acc:\n","        print('Saving..')\n","        state = {\n","            'net': net.state_dict(),\n","            'acc': acc,\n","            'epoch': epoch,\n","        }\n","        if not os.path.isdir('checkpoint'):\n","            os.mkdir('checkpoint')\n","        torch.save(state, './checkpoint/ckpt.pth')\n","        best_acc = acc\n","\n","summary(net, (3, 32, 32))\n","print(net)\n","\n","for epoch in range(start_epoch, start_epoch+50):\n","    train(epoch)\n","    test(epoch)\n","    scheduler.step()"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting pytorch-cifar/main.py\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mn3-TGkFksln","executionInfo":{"status":"ok","timestamp":1690833135896,"user_tz":240,"elapsed":194392,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}},"outputId":"81b44680-677a-4673-cfd8-0055ad8207ff"},"source":["!python3 pytorch-cifar/main.py"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n","==> Building model..\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,728\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","            Conv2d-3           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-4           [-1, 64, 32, 32]             128\n","            Conv2d-5           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-6           [-1, 64, 32, 32]             128\n","        BasicBlock-7           [-1, 64, 32, 32]               0\n","            Conv2d-8           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-9           [-1, 64, 32, 32]             128\n","           Conv2d-10           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-11           [-1, 64, 32, 32]             128\n","       BasicBlock-12           [-1, 64, 32, 32]               0\n","           Conv2d-13          [-1, 128, 16, 16]          73,728\n","      BatchNorm2d-14          [-1, 128, 16, 16]             256\n","           Conv2d-15          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-16          [-1, 128, 16, 16]             256\n","           Conv2d-17          [-1, 128, 16, 16]           8,192\n","      BatchNorm2d-18          [-1, 128, 16, 16]             256\n","       BasicBlock-19          [-1, 128, 16, 16]               0\n","           Conv2d-20          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-21          [-1, 128, 16, 16]             256\n","           Conv2d-22          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-23          [-1, 128, 16, 16]             256\n","       BasicBlock-24          [-1, 128, 16, 16]               0\n","           Conv2d-25            [-1, 256, 8, 8]         294,912\n","      BatchNorm2d-26            [-1, 256, 8, 8]             512\n","           Conv2d-27            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-28            [-1, 256, 8, 8]             512\n","           Conv2d-29            [-1, 256, 8, 8]          32,768\n","      BatchNorm2d-30            [-1, 256, 8, 8]             512\n","       BasicBlock-31            [-1, 256, 8, 8]               0\n","           Conv2d-32            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-33            [-1, 256, 8, 8]             512\n","           Conv2d-34            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-35            [-1, 256, 8, 8]             512\n","       BasicBlock-36            [-1, 256, 8, 8]               0\n","           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n","      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n","           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n","           Conv2d-41            [-1, 512, 4, 4]         131,072\n","      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n","       BasicBlock-43            [-1, 512, 4, 4]               0\n","           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n","           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n","       BasicBlock-48            [-1, 512, 4, 4]               0\n","           Linear-49                   [-1, 10]           5,130\n","           ResNet-50                   [-1, 10]               0\n","================================================================\n","Total params: 11,173,962\n","Trainable params: 11,173,962\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 11.25\n","Params size (MB): 42.63\n","Estimated Total Size (MB): 53.89\n","----------------------------------------------------------------\n","DataParallel(\n","  (module): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential()\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential()\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential()\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential()\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (shortcut): Sequential()\n","      )\n","    )\n","    (linear): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","\n","Epoch: 0\n"," [================================================================>]  Step: 1s691ms | Tot: 39s778ms | Loss: 2.105 | Acc: 26.356% (13178/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 3s331ms | Loss: 1.677 | Acc: 37.150% (3715/10000) 100/100 \n","Saving..\n","\n","Epoch: 1\n"," [================================================================>]  Step: 63ms | Tot: 39s593ms | Loss: 1.552 | Acc: 42.374% (21187/50000) 391/391 \n"," [================================================================>]  Step: 28ms | Tot: 3s289ms | Loss: 1.521 | Acc: 45.550% (4555/10000) 100/100 \n","Saving..\n","\n","Epoch: 2\n"," [================================================================>]  Step: 65ms | Tot: 40s202ms | Loss: 1.275 | Acc: 53.638% (26819/50000) 391/391 \n"," [================================================================>]  Step: 27ms | Tot: 3s301ms | Loss: 1.337 | Acc: 52.610% (5261/10000) 100/100 \n","Saving..\n","\n","Epoch: 3\n"," [================================================================>]  Step: 66ms | Tot: 40s676ms | Loss: 1.033 | Acc: 62.960% (31480/50000) 391/391 \n"," [================================================================>]  Step: 27ms | Tot: 3s731ms | Loss: 1.073 | Acc: 63.130% (6313/10000) 100/100 \n","Saving..\n","\n","Epoch: 4\n","Traceback (most recent call last):\n","  File \"/content/pytorch-cifar/main.py\", line 144, in <module>\n","    train(epoch)\n","  File \"/content/pytorch-cifar/main.py\", line 97, in train\n","    train_loss += loss.item()\n","KeyboardInterrupt\n","^C\n"]}]}]}