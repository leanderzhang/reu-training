{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNCtGMS+pDb3X/XOHhR7WU8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","print(torch.__version__)\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","print('Using PyTorch version:', torch.__version__, ' Device:', device)\n","\n","batch_size = 32\n","\n","train_dataset = datasets.MNIST('./data',\n","                               train=True,\n","                               download=True,\n","                               transform=transforms.ToTensor())\n","\n","validation_dataset = datasets.MNIST('./data',\n","                                    train=False,\n","                                    transform=transforms.ToTensor())\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,\n","                                                batch_size=batch_size,\n","                                                shuffle=False)\n","\n","for (X_train, y_train) in train_loader:\n","    print('X_train:', X_train.size(), 'type:', X_train.type())\n","    print('y_train:', y_train.size(), 'type:', y_train.type())\n","    break\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(28*28, 16)\n","        self.fc2 = nn.Linear(16, 16)\n","        self.fc3 = nn.Linear(16, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return F.log_softmax(self.fc3(x), dim=1)\n","\n","model = Net().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n","criterion = nn.CrossEntropyLoss()\n","\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ca-HI5QEDaS","executionInfo":{"status":"ok","timestamp":1690843211967,"user_tz":240,"elapsed":4423,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}},"outputId":"849e5572-6260-4eb2-e9a9-3d08c43e8997"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n","Using PyTorch version: 2.0.1+cu118  Device: cpu\n","X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n","y_train: torch.Size([32]) type: torch.LongTensor\n","Net(\n","  (fc1): Linear(in_features=784, out_features=16, bias=True)\n","  (fc2): Linear(in_features=16, out_features=16, bias=True)\n","  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["def train(epoch, log_interval=200):\n","    # Set model to training mode\n","    model.train()\n","\n","    # Loop over each batch from the training set\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Copy data to GPU if needed\n","        data = data.to(device)\n","        target = target.to(device)\n","\n","        # Zero gradient buffers\n","        optimizer.zero_grad()\n","\n","        # Pass data through the network\n","        output = model(data)\n","\n","        # Calculate loss\n","        loss = criterion(output, target)\n","\n","        # Backpropagate\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()\n","\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.data.item()))\n","def validate(loss_vector, accuracy_vector):\n","    model.eval()\n","    val_loss, correct = 0, 0\n","    for data, target in validation_loader:\n","        data = data.to(device)\n","        target = target.to(device)\n","        output = model(data)\n","        val_loss += criterion(output, target).data.item()\n","        pred = output.data.max(1)[1] # get the index of the max log-probability\n","        correct += pred.eq(target.data).cpu().sum()\n","\n","    val_loss /= len(validation_loader)\n","    loss_vector.append(val_loss)\n","\n","    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n","    accuracy_vector.append(accuracy)\n","\n","    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        val_loss, correct, len(validation_loader.dataset), accuracy))"],"metadata":{"id":"hgM7aJPOElky","executionInfo":{"status":"ok","timestamp":1690843211969,"user_tz":240,"elapsed":9,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","\n","lossv, accv = [], []\n","for epoch in range(1, epochs + 1):\n","    train(epoch)\n","    validate(lossv, accv)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGEWF4xaEoc9","executionInfo":{"status":"ok","timestamp":1690843274138,"user_tz":240,"elapsed":62175,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}},"outputId":"1938365e-73e6-46b8-ffeb-cd8c7716901f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298854\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.977734\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.244394\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.791230\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.707093\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.478044\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.414540\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.250297\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.384215\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.551589\n","\n","Validation set: Average loss: 0.3600, Accuracy: 8967/10000 (90%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.448805\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.270290\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.204037\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.347269\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.353995\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.139851\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.056438\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.099213\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.300724\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.461864\n","\n","Validation set: Average loss: 0.2856, Accuracy: 9200/10000 (92%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.318934\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.466895\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.272572\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.275100\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.155693\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.178689\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.050521\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.133348\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.155977\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.234439\n","\n","Validation set: Average loss: 0.2442, Accuracy: 9307/10000 (93%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.052722\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.048615\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.164531\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.205968\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.032157\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.241177\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.250705\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.433350\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.103758\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.098873\n","\n","Validation set: Average loss: 0.2205, Accuracy: 9340/10000 (93%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.450631\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.087018\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.126621\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.195715\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.118083\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.033085\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.358213\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.110727\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.218693\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.039188\n","\n","Validation set: Average loss: 0.2025, Accuracy: 9395/10000 (94%)\n","\n"]}]}]}