{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pX5ARKKkUiIvcW4KVmyIoN7dL6BApPSk","timestamp":1690832109234}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#Import Libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import keras\n","from tensorflow.keras import datasets,models,layers"],"metadata":{"id":"mwOs9IXqaRPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D12UUuRAaLYP","executionInfo":{"status":"ok","timestamp":1690895919969,"user_tz":240,"elapsed":9878,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef28c30e-5aad-40fe-8321-e209efdcc8d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 6s 0us/step\n","(50000, 32, 32, 3)\n"]}],"source":["# Adding TF Cifar10 Data ..\n","from keras.datasets import cifar10\n","(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n","print(X_train.shape)\n","X_train, Y_train = X_train[:10000,:,:,:], Y_train[:10000,:]"]},{"cell_type":"code","source":["X_train, Y_train = X_train[:10000,:,:,:], Y_train[:10000,:]"],"metadata":{"id":"BsCH1V2WaS5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Y_train[-10:])\n","print(X_train.shape)\n","print(X_train[0,:,:,0])\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255.0\n","X_test /= 255.0"],"metadata":{"id":"UFICtrTKaS7g","executionInfo":{"status":"ok","timestamp":1690895922075,"user_tz":240,"elapsed":2,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}},"outputId":"22c42b7c-a942-46df-9845-7535b4f4dcc8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[9]\n"," [2]\n"," [2]\n"," [1]\n"," [6]\n"," [3]\n"," [9]\n"," [1]\n"," [1]\n"," [5]]\n","(10000, 32, 32, 3)\n","[[ 59  43  50 ... 158 152 148]\n"," [ 16   0  18 ... 123 119 122]\n"," [ 25  16  49 ... 118 120 109]\n"," ...\n"," [208 201 198 ... 160  56  53]\n"," [180 173 186 ... 184  97  83]\n"," [177 168 179 ... 216 151 123]]\n"]}]},{"cell_type":"code","source":["def normalize_img_one_hot(image, label):\n","  return image ,tf.one_hot(label, 10)\n","\n","X_train, Y_train = normalize_img_one_hot(X_train,Y_train)"],"metadata":{"id":"ujBhV-DOaS9g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","print(X_train.shape)\n","print(Y_train.shape)\n","Y_train = Y_train[:,0,:]\n"],"metadata":{"id":"XiXPc-mTaS_1","executionInfo":{"status":"ok","timestamp":1690895926361,"user_tz":240,"elapsed":238,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}},"outputId":"91692514-fa8d-435f-fc20-6f98b33f6da9","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 32, 32, 3)\n","(10000, 1, 10)\n"]}]},{"cell_type":"code","source":["\"\"\"\n","ResNet-50\n","Reference:\n","[1] K. He et al. Deep Residual Learning for Image Recognition. CVPR, 2016\n","[2] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers:\n","Surpassing human-level performance on imagenet classification. In\n","ICCV, 2015.\n","\"\"\"\n","\n","\n","from keras.callbacks import EarlyStopping\n","from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n","from keras.models import Sequential\n","from keras.models import Model\n","import tensorflow as tf\n","\n","\n","class BottleNeck(Model):\n","    \"\"\"\n","    resnet bottleneeck block\n","    \"\"\"\n","    def __init__(self, channels: int, down_sample=False):\n","      super().__init__()\n","      self.__channels = channels\n","      self.__down_sample = down_sample\n","      self.__strides = [2, 1] if down_sample else [1, 1]\n","\n","      KERNEL_SIZE = (3, 3)\n","      INIT_SCHEME = \"glorot_uniform\"\n","\n","      self.conv_1 = Conv2D(self.__channels/4, strides=self.__strides[0],\n","                            kernel_size=(1,1), padding=\"same\", kernel_initializer=INIT_SCHEME, use_bias=False)\n","      self.bn_1 = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","      self.conv_2 = Conv2D(self.__channels/4, strides=self.__strides[1],kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME, use_bias=False)\n","      self.bn_2 = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","      self.conv_3 = Conv2D(self.__channels, strides=self.__strides[1],\n","                            kernel_size=(1,1), padding=\"same\", kernel_initializer=INIT_SCHEME, use_bias=False)\n","      self.bn_3 = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","      self.merge = Add()\n","\n","      if self.__down_sample:\n","          # first block of each block cluster, image size decrease, channel increase\n","          self.res_conv = Conv2D(self.__channels, strides=self.__strides[0],\n","                            kernel_size=(1,1), padding=\"same\", kernel_initializer=INIT_SCHEME, use_bias=False)\n","          self.res_bn = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","\n","    def call(self, inputs):\n","      res = inputs\n","\n","      x = self.conv_1(inputs)\n","      x = self.bn_1(x)\n","      x = tf.nn.relu(x)\n","      x = self.conv_2(x)\n","      x = self.bn_2(x)\n","      x = tf.nn.relu(x)\n","      x = self.conv_3(x)\n","      x = self.bn_3(x)\n","\n","      if self.__down_sample:\n","          # print(res.shape)\n","          res = self.res_conv(res)\n","          # print(res.shape)\n","          res = self.res_bn(res)\n","\n","      # if not perform down sample, then add a shortcut directly\n","      x = self.merge([x, res])\n","      out = tf.nn.relu(x)\n","\n","      return out\n","\n","\n","class ResNet50(Model):\n","\n","    def __init__(self, num_classes, **kwargs):\n","        \"\"\"\n","            num_classes: number of classes in specific classification task.\n","        \"\"\"\n","        super().__init__(**kwargs)\n","        self.conv_1 = Conv2D(64, (7, 7),padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=False)\n","        self.init_bn = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","        # self.pool_2 = MaxPool2D(pool_size=(3, 3), strides=2, padding=\"same\")\n","\n","        # first half of stage 1\n","        self.conv_s1_1 = Conv2D(64, strides=1,kernel_size=(1,1), padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=False)\n","        self.bn_s1_1 = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","        self.conv_s1_2 = Conv2D(64, strides=1,kernel_size=(3,3), padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=False)\n","        self.bn_s1_2 = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","        self.conv_s1_3 = Conv2D(256, strides=1,kernel_size=(1,1), padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=False)\n","        self.bn_s1_3 = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","        self.side_conv_s1 = Conv2D(256, strides=1,kernel_size=(1,1), padding=\"same\", kernel_initializer=\"glorot_uniform\", use_bias=False)\n","        self.side_bn_s1 = BatchNormalization(axis=-1, momentum=0, epsilon=0.001)\n","        self.merge = Add()\n","\n","        # stage 1\n","        self.res_1_2 = BottleNeck(256)\n","        self.res_1_3 = BottleNeck(256)\n","\n","        # stage 2\n","        self.res_2_1 = BottleNeck(512, down_sample=True)\n","        self.res_2_2 = BottleNeck(512)\n","        self.res_2_3 = BottleNeck(512)\n","\n","        # stage 3\n","        self.res_3_1 = BottleNeck(1024, down_sample = True)\n","        self.res_3_2 = BottleNeck(1024)\n","        self.res_3_3 = BottleNeck(1024)\n","\n","        # stage 4\n","        self.res_4_1 = BottleNeck(2048, down_sample = True)\n","        self.res_4_2 = BottleNeck(2048)\n","        self.res_4_3 = BottleNeck(2048)\n","        # self.avg_pool = GlobalAveragePooling2D()\n","        self.flat = Flatten()\n","        self.fc = Dense(num_classes, activation=\"softmax\", use_bias = False)\n","\n","    def call(self, inputs):\n","        out = self.conv_1(inputs)\n","        out = self.init_bn(out)\n","        out = tf.nn.relu(out)\n","        # out = self.pool_2(out)\n","\n","        res = self.side_conv_s1(out)\n","        res = self.side_bn_s1(res)\n","        # first helf of stage 1\n","        out = self.conv_s1_1(out)\n","        out = self.bn_s1_1(out)\n","        out = tf.nn.relu(out)\n","        out = self.conv_s1_2(out)\n","        out = self.bn_s1_2(out)\n","        out = tf.nn.relu(out)\n","        out = self.conv_s1_3(out)\n","        out = self.bn_s1_3(out)\n","        out = self.merge([out,res])\n","\n","\n","        for res_block in [self.res_1_2, self.res_1_3, self.res_2_1, self.res_2_2, self.res_2_3, self.res_3_1, self.res_3_2, self.res_3_3, self.res_4_1, self.res_4_2, self.res_4_3]:\n","            out = res_block(out)\n","        # out = self.avg_pool(out)\n","        out = self.flat(out)\n","        # print(out.shape)\n","        out = self.fc(out)\n","        # print(out.shape)\n","        print(\"done out\")\n","        return out"],"metadata":{"id":"dAGmuMhaaTCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ResNet50(10)\n","model.build(input_shape = (None,32,32,3))\n","\n","#use categorical_crossentropy since the label is one-hot encoded\n","from tensorflow.keras.optimizers import SGD\n","opt = SGD(learning_rate=0.1,momentum=0.9) #parameters suggested by He [1]\n","loss_fn2=tf.keras.losses.CategoricalCrossentropy()\n","\n","model.compile(optimizer = opt, loss=loss_fn2, metrics=[\"accuracy\"])\n","model.summary()"],"metadata":{"id":"RpHGLTDKaTEK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d3b7299-2b78-467b-b5fe-41385cd3139c","executionInfo":{"status":"ok","timestamp":1690895893823,"user_tz":240,"elapsed":1452,"user":{"displayName":"Stephen Qiu","userId":"08150546758401848037"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <bound method BottleNeck.call of <__main__.BottleNeck object at 0x7dd60815ba60>> and will run it as-is.\n","Cause: mangled names are not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <bound method BottleNeck.call of <__main__.BottleNeck object at 0x7dd60815ba60>> and will run it as-is.\n","Cause: mangled names are not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","(None, 32, 32, 256)\n","(None, 16, 16, 512)\n","(None, 16, 16, 512)\n","(None, 8, 8, 1024)\n","(None, 8, 8, 1024)\n","(None, 4, 4, 2048)\n","(None, 32768)\n","(None, 10)\n","done out\n","Model: \"res_net50_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_82 (Conv2D)          multiple                  9408      \n","                                                                 \n"," batch_normalization_82 (Bat  multiple                 256       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_83 (Conv2D)          multiple                  4096      \n","                                                                 \n"," batch_normalization_83 (Bat  multiple                 256       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_84 (Conv2D)          multiple                  36864     \n","                                                                 \n"," batch_normalization_84 (Bat  multiple                 256       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_85 (Conv2D)          multiple                  16384     \n","                                                                 \n"," batch_normalization_85 (Bat  multiple                 1024      \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_86 (Conv2D)          multiple                  16384     \n","                                                                 \n"," batch_normalization_86 (Bat  multiple                 1024      \n"," chNormalization)                                                \n","                                                                 \n"," add_24 (Add)                multiple                  0         \n","                                                                 \n"," bottle_neck_22 (BottleNeck)  multiple                 71168     \n","                                                                 \n"," bottle_neck_23 (BottleNeck)  multiple                 71168     \n","                                                                 \n"," bottle_neck_24 (BottleNeck)  multiple                 381952    \n","                                                                 \n"," bottle_neck_25 (BottleNeck)  multiple                 281600    \n","                                                                 \n"," bottle_neck_26 (BottleNeck)  multiple                 281600    \n","                                                                 \n"," bottle_neck_27 (BottleNeck)  multiple                 1517568   \n","                                                                 \n"," bottle_neck_28 (BottleNeck)  multiple                 1120256   \n","                                                                 \n"," bottle_neck_29 (BottleNeck)  multiple                 1120256   \n","                                                                 \n"," bottle_neck_30 (BottleNeck)  multiple                 6049792   \n","                                                                 \n"," bottle_neck_31 (BottleNeck)  multiple                 4468736   \n","                                                                 \n"," bottle_neck_32 (BottleNeck)  multiple                 4468736   \n","                                                                 \n"," flatten_2 (Flatten)         multiple                  0         \n","                                                                 \n"," dense_2 (Dense)             multiple                  327680    \n","                                                                 \n","=================================================================\n","Total params: 20,246,464\n","Trainable params: 20,204,096\n","Non-trainable params: 42,368\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping\n","\n","es = EarlyStopping(patience= 8, restore_best_weights=True, monitor=\"val_accuracy\")\n","#I did not use cross validation, so the validate performance is not accurate.\n","STEPS = len(X_train) / 128\n","history = model.fit(X_train,Y_train, batch_size = 128, epochs=500, validation_data=(X_train, Y_train),callbacks=[es])"],"metadata":{"id":"GBUJPA7Nj3RV"},"execution_count":null,"outputs":[]}]}